{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECCIÓN 1: Importación de bibliotecas\n",
    "\n",
    "En esta sección importamos todas las bibliotecas y funciones necesarias para el análisis y modelado de los datos. Se importan bibliotecas comunes como pandas y sklearn, así como bibliotecas más específicas para modelos de machine learning como LightGBM y XGBoost.\n",
    "\n",
    "Además, se importan varias funciones de sklearn para el preprocesamiento de los datos, como `RobustScaler` y `OneHotEncoder`, así como para la creación de pipelines y la transformación de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECCIÓN 2: Carga de datos y establecimiento de semilla\n",
    "\n",
    "En esta sección cargamos el dataset que se utilizará para el análisis y modelado. Se utiliza la función `read_parquet` de pandas para cargar un archivo en formato Parquet. Tambien se establece una semilla para trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"dataset.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>monthly_inhand_salary</th>\n",
       "      <th>num_bank_accounts</th>\n",
       "      <th>num_credit_card</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>num_of_loan</th>\n",
       "      <th>delay_from_due_date</th>\n",
       "      <th>...</th>\n",
       "      <th>num_credit_inquiries</th>\n",
       "      <th>outstanding_debt</th>\n",
       "      <th>credit_utilization_ratio</th>\n",
       "      <th>credit_history_age</th>\n",
       "      <th>payment_of_min_amount</th>\n",
       "      <th>total_emi_per_month</th>\n",
       "      <th>amount_invested_monthly</th>\n",
       "      <th>payment_behaviour</th>\n",
       "      <th>monthly_balance</th>\n",
       "      <th>credit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUS_0xd40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>809.98</td>\n",
       "      <td>23.933795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>24.785217</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>358.124168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUS_0x21b1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>34847.84</td>\n",
       "      <td>3037.986667</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>605.03</td>\n",
       "      <td>32.933856</td>\n",
       "      <td>27.0</td>\n",
       "      <td>No</td>\n",
       "      <td>18.816215</td>\n",
       "      <td>218.904344</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>356.078109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUS_0x2dbc</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>143162.64</td>\n",
       "      <td>12187.220000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1303.01</td>\n",
       "      <td>38.374753</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No</td>\n",
       "      <td>246.992319</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>895.494583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUS_0xb891</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Entrepreneur</td>\n",
       "      <td>30689.89</td>\n",
       "      <td>2612.490833</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>632.46</td>\n",
       "      <td>27.332515</td>\n",
       "      <td>17.0</td>\n",
       "      <td>No</td>\n",
       "      <td>16.415452</td>\n",
       "      <td>125.617251</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>379.216381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUS_0x1cdb</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Developer</td>\n",
       "      <td>35547.71</td>\n",
       "      <td>2853.309167</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>943.86</td>\n",
       "      <td>25.862922</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.330901</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>364.000016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>CUS_0x372c</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>42903.79</td>\n",
       "      <td>3468.315833</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1079.48</td>\n",
       "      <td>35.716618</td>\n",
       "      <td>28.0</td>\n",
       "      <td>No</td>\n",
       "      <td>34.975457</td>\n",
       "      <td>115.184984</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>CUS_0xf16</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Media_Manager</td>\n",
       "      <td>16680.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>897.16</td>\n",
       "      <td>41.212367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>41.113561</td>\n",
       "      <td>70.805550</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>CUS_0xaf61</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Writer</td>\n",
       "      <td>37188.10</td>\n",
       "      <td>3097.008333</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>620.64</td>\n",
       "      <td>39.300980</td>\n",
       "      <td>30.0</td>\n",
       "      <td>No</td>\n",
       "      <td>84.205949</td>\n",
       "      <td>42.935566</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>CUS_0x8600</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Architect</td>\n",
       "      <td>20002.88</td>\n",
       "      <td>1929.906667</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3571.70</td>\n",
       "      <td>37.140784</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>60.964772</td>\n",
       "      <td>34.662906</td>\n",
       "      <td>High_spent_Large_value_payments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>CUS_0x942c</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Mechanic</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>502.38</td>\n",
       "      <td>34.192463</td>\n",
       "      <td>31.0</td>\n",
       "      <td>No</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>167.163865</td>\n",
       "      <td>!@9#%8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id   age     occupation  annual_income  monthly_inhand_salary  \\\n",
       "0       CUS_0xd40  23.0      Scientist       19114.12            1824.843333   \n",
       "1      CUS_0x21b1  28.0        Teacher       34847.84            3037.986667   \n",
       "2      CUS_0x2dbc  34.0       Engineer      143162.64           12187.220000   \n",
       "3      CUS_0xb891  55.0   Entrepreneur       30689.89            2612.490833   \n",
       "4      CUS_0x1cdb  21.0      Developer       35547.71            2853.309167   \n",
       "...           ...   ...            ...            ...                    ...   \n",
       "12495  CUS_0x372c  19.0         Lawyer       42903.79            3468.315833   \n",
       "12496   CUS_0xf16  45.0  Media_Manager       16680.35                    NaN   \n",
       "12497  CUS_0xaf61  50.0         Writer       37188.10            3097.008333   \n",
       "12498  CUS_0x8600  29.0      Architect       20002.88            1929.906667   \n",
       "12499  CUS_0x942c  25.0       Mechanic       39628.99            3359.415833   \n",
       "\n",
       "       num_bank_accounts  num_credit_card  interest_rate  num_of_loan  \\\n",
       "0                      3                4              3          4.0   \n",
       "1                      2                4              6          1.0   \n",
       "2                      1                5              8          3.0   \n",
       "3                      2                5              4       -100.0   \n",
       "4                      7                5              5       -100.0   \n",
       "...                  ...              ...            ...          ...   \n",
       "12495                  0                4              6          1.0   \n",
       "12496                  1                1              5          4.0   \n",
       "12497                  1                4              5          3.0   \n",
       "12498                 10                8             29          5.0   \n",
       "12499                  4                6              7          2.0   \n",
       "\n",
       "       delay_from_due_date  ...  num_credit_inquiries  outstanding_debt  \\\n",
       "0                        3  ...                   4.0            809.98   \n",
       "1                        3  ...                   2.0            605.03   \n",
       "2                        8  ...                   3.0           1303.01   \n",
       "3                        4  ...                   4.0            632.46   \n",
       "4                        1  ...                   4.0            943.86   \n",
       "...                    ...  ...                   ...               ...   \n",
       "12495                    9  ...                   1.0           1079.48   \n",
       "12496                    1  ...                   8.0            897.16   \n",
       "12497                    7  ...                   3.0            620.64   \n",
       "12498                   33  ...                   9.0           3571.70   \n",
       "12499                   18  ...                   3.0            502.38   \n",
       "\n",
       "       credit_utilization_ratio  credit_history_age  payment_of_min_amount  \\\n",
       "0                     23.933795                 NaN                     No   \n",
       "1                     32.933856                27.0                     No   \n",
       "2                     38.374753                18.0                     No   \n",
       "3                     27.332515                17.0                     No   \n",
       "4                     25.862922                31.0                    Yes   \n",
       "...                         ...                 ...                    ...   \n",
       "12495                 35.716618                28.0                     No   \n",
       "12496                 41.212367                 NaN                     No   \n",
       "12497                 39.300980                30.0                     No   \n",
       "12498                 37.140784                 6.0                    Yes   \n",
       "12499                 34.192463                31.0                     No   \n",
       "\n",
       "       total_emi_per_month amount_invested_monthly  \\\n",
       "0                49.574949               24.785217   \n",
       "1                18.816215              218.904344   \n",
       "2               246.992319            10000.000000   \n",
       "3                16.415452              125.617251   \n",
       "4                 0.000000              181.330901   \n",
       "...                    ...                     ...   \n",
       "12495            34.975457              115.184984   \n",
       "12496            41.113561               70.805550   \n",
       "12497            84.205949               42.935566   \n",
       "12498            60.964772               34.662906   \n",
       "12499            35.104023              167.163865   \n",
       "\n",
       "                      payment_behaviour  monthly_balance credit_score  \n",
       "0      High_spent_Medium_value_payments       358.124168            0  \n",
       "1        Low_spent_Small_value_payments       356.078109            0  \n",
       "2       High_spent_Small_value_payments       895.494583            0  \n",
       "3       High_spent_Small_value_payments       379.216381            0  \n",
       "4       High_spent_Small_value_payments       364.000016            0  \n",
       "...                                 ...              ...          ...  \n",
       "12495  High_spent_Medium_value_payments              NaN            0  \n",
       "12496    Low_spent_Large_value_payments              NaN            0  \n",
       "12497  High_spent_Medium_value_payments              NaN            0  \n",
       "12498   High_spent_Large_value_payments              NaN            0  \n",
       "12499                            !@9#%8              NaN            1  \n",
       "\n",
       "[12500 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECCIÓN 3: Limpieza y preprocesamiento de los datos\n",
    "\n",
    "Definimos una función de preprocesamiento de los datos. La función `clean_dataset` realiza varias tareas:\n",
    "1. Hace una copia del DataFrame para no modificar los datos originales.\n",
    "2. Filtra los datos para excluir filas que no cumplen con ciertos criterios. Por ejemplo, filtra a las personas que tienen una edad menor a 0 o mayor a 120, que tienen un número negativo de cuentas bancarias, entre otros.\n",
    "3. Convierte la columna 'occupation' a strings.\n",
    "4. Excluye las filas en las que el campo 'payment_behaviour' es igual a '9#%8'.\n",
    "5. En función del argumento `erase_nm`, reemplaza el valor 'NM' en la columna 'payment_of_min_amount' por 'no' o excluye las filas que contienen 'NM'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df: pd.DataFrame, erase_nm: bool= True, erase_null: bool= True) -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses the data\"\"\"\n",
    "    data = df.copy()\n",
    "    query_string = (\n",
    "        \"age > 0 and \"\n",
    "        \"age <= 120 and \"\n",
    "        \"num_bank_accounts >= 0 and \"\n",
    "        \"num_of_loan >= 0 and \"\n",
    "        \"num_of_delayed_payment >= 0 and \"\n",
    "        \"monthly_balance >= 0\"\n",
    "    )\n",
    "    data = data.query(query_string)\n",
    "    data.loc[:, \"occupation\"] = data[\"occupation\"].astype(str)\n",
    "    data = data[data[\"payment_behaviour\"] != \"9#%8\"]\n",
    "    if erase_nm:\n",
    "        data.loc[:, \"payment_of_min_amount\"] = data[\"payment_of_min_amount\"].replace(\"NM\", \"no\")\n",
    "    else:\n",
    "        data = data[df[\"payment_of_min_amount\"] != \"NM\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se limpia el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define un pipeline donde se escalan los valores numericos y se transforman las variables categoricas a OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las listas de características numéricas y categóricas\n",
    "numeric_features = [\n",
    "    \"age\",\n",
    "    \"annual_income\",\n",
    "    \"monthly_inhand_salary\",\n",
    "    \"num_bank_accounts\",\n",
    "    \"num_credit_card\",\n",
    "    \"interest_rate\",\n",
    "    \"num_of_loan\",\n",
    "    \"delay_from_due_date\",\n",
    "    \"num_of_delayed_payment\",\n",
    "    \"changed_credit_limit\",\n",
    "    \"num_credit_inquiries\",\n",
    "    \"outstanding_debt\",\n",
    "    \"credit_utilization_ratio\",\n",
    "    \"credit_history_age\",\n",
    "    \"total_emi_per_month\",\n",
    "    \"amount_invested_monthly\",\n",
    "    \"monthly_balance\",\n",
    "]\n",
    "\n",
    "categorical_features = [\"occupation\", \"payment_behaviour\", \"payment_of_min_amount\"]\n",
    "\n",
    "# Definir los transformadores para datos numéricos y categóricos\n",
    "numeric_transformer = RobustScaler()\n",
    "categorical_transformer = OneHotEncoder(sparse_output=False, handle_unknown= 'ignore')\n",
    "\n",
    "# Crear el preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),  # Aplicar el preprocesamiento\n",
    "    ('imputer', SimpleImputer(strategy='median'))  # Asegurarse de que no haya NaN\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECCIÓN 4: Definición de baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir el baseline, se hacen 2 conjuntos, uno de training y uno de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"credit_score\"])\n",
    "y = df[[\"credit_score\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size= 0.1, random_state= 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se entrenan 8 clasificadores para definir un pipeline y elegir los mejores modelos para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Dummy\n",
      "Entrenado Dummy\n",
      "Classification Report for Dummy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69       736\n",
      "           1       0.26      0.24      0.25       316\n",
      "\n",
      "    accuracy                           0.56      1052\n",
      "   macro avg       0.47      0.47      0.47      1052\n",
      "weighted avg       0.55      0.56      0.56      1052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Entrenando Logistic Regression\n",
      "Entrenado Logistic Regression\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83       736\n",
      "           1       0.61      0.31      0.41       316\n",
      "\n",
      "    accuracy                           0.73      1052\n",
      "   macro avg       0.68      0.61      0.62      1052\n",
      "weighted avg       0.71      0.73      0.70      1052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Entrenando K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasceballos/anaconda3/envs/ml/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenado K-Nearest Neighbors\n",
      "Classification Report for K-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.81       736\n",
      "           1       0.53      0.39      0.45       316\n",
      "\n",
      "    accuracy                           0.71      1052\n",
      "   macro avg       0.65      0.62      0.63      1052\n",
      "weighted avg       0.69      0.71      0.70      1052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Entrenando Decision Tree\n",
      "Entrenado Decision Tree\n",
      "Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       736\n",
      "           1       0.47      0.51      0.49       316\n",
      "\n",
      "    accuracy                           0.68      1052\n",
      "   macro avg       0.63      0.63      0.63      1052\n",
      "weighted avg       0.69      0.68      0.69      1052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Entrenando SVM\n",
      "Entrenado SVM\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82       736\n",
      "           1       0.00      0.00      0.00       316\n",
      "\n",
      "    accuracy                           0.70      1052\n",
      "   macro avg       0.35      0.50      0.41      1052\n",
      "weighted avg       0.49      0.70      0.58      1052\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasceballos/anaconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tomasceballos/anaconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tomasceballos/anaconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tomasceballos/anaconda3/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Random Forest\n",
      "Entrenado Random Forest\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       736\n",
      "           1       0.63      0.49      0.55       316\n",
      "\n",
      "    accuracy                           0.76      1052\n",
      "   macro avg       0.72      0.68      0.69      1052\n",
      "weighted avg       0.75      0.76      0.75      1052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 2741, number of negative: 6722\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2626\n",
      "[LightGBM] [Info] Number of data points in the train set: 9463, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289654 -> initscore=-0.897063\n",
      "[LightGBM] [Info] Start training from score -0.897063\n",
      "Entrenando LightGBM\n",
      "Entrenado LightGBM\n",
      "Classification Report for LightGBM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       736\n",
      "           1       0.64      0.53      0.58       316\n",
      "\n",
      "    accuracy                           0.77      1052\n",
      "   macro avg       0.73      0.70      0.71      1052\n",
      "weighted avg       0.76      0.77      0.76      1052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Entrenando XGBoost\n",
      "Entrenado XGBoost\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       736\n",
      "           1       0.63      0.53      0.57       316\n",
      "\n",
      "    accuracy                           0.77      1052\n",
      "   macro avg       0.72      0.70      0.71      1052\n",
      "weighted avg       0.76      0.77      0.76      1052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Results sorted by Accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>LGBMClassifier(random_state=42)</td>\n",
       "      <td>0.769962</td>\n",
       "      <td>0.642308</td>\n",
       "      <td>0.528481</td>\n",
       "      <td>0.579861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.765209</td>\n",
       "      <td>0.631179</td>\n",
       "      <td>0.525316</td>\n",
       "      <td>0.573402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>0.733840</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.310127</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.711977</td>\n",
       "      <td>0.528139</td>\n",
       "      <td>0.386076</td>\n",
       "      <td>0.446069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SVC(random_state=42)</td>\n",
       "      <td>0.699620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>0.682510</td>\n",
       "      <td>0.473529</td>\n",
       "      <td>0.509494</td>\n",
       "      <td>0.490854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>DummyClassifier(random_state=42, strategy='str...</td>\n",
       "      <td>0.561787</td>\n",
       "      <td>0.255892</td>\n",
       "      <td>0.240506</td>\n",
       "      <td>0.247961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model_name                                              Model  \\\n",
       "6             LightGBM                    LGBMClassifier(random_state=42)   \n",
       "7              XGBoost  XGBClassifier(base_score=None, booster=None, c...   \n",
       "5        Random Forest  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "1  Logistic Regression                LogisticRegression(random_state=42)   \n",
       "2  K-Nearest Neighbors                    KNeighborsClassifier(n_jobs=-1)   \n",
       "4                  SVM                               SVC(random_state=42)   \n",
       "3        Decision Tree            DecisionTreeClassifier(random_state=42)   \n",
       "0                Dummy  DummyClassifier(random_state=42, strategy='str...   \n",
       "\n",
       "   Accuracy  Precision    Recall  F1-score  \n",
       "6  0.769962   0.642308  0.528481  0.579861  \n",
       "7  0.765209   0.631179  0.525316  0.573402  \n",
       "5  0.760456   0.629032  0.493671  0.553191  \n",
       "1  0.733840   0.612500  0.310127  0.411765  \n",
       "2  0.711977   0.528139  0.386076  0.446069  \n",
       "4  0.699620   0.000000  0.000000  0.000000  \n",
       "3  0.682510   0.473529  0.509494  0.490854  \n",
       "0  0.561787   0.255892  0.240506  0.247961  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocesar las características utilizando el preprocessor\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train)\n",
    "X_test_preprocessed = pipeline.transform(X_test)\n",
    "y_train = y_train.values.flatten()\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "# Crear una lista para almacenar los resultados de las métricas\n",
    "metric_results = []\n",
    "\n",
    "# Definir los clasificadores\n",
    "classifiers = {\n",
    "    \"Dummy\": DummyClassifier(strategy=\"stratified\", random_state=seed),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=seed),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_jobs=-1),  # KNeighborsClassifier no tiene parámetro 'random_state'\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=seed),\n",
    "    \"SVM\": SVC(random_state=seed),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=seed),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=seed),\n",
    "    \"XGBoost\": XGBClassifier(random_state=seed, eval_metric=\"logloss\"),\n",
    "}\n",
    "\n",
    "# Iterar sobre los clasificadores\n",
    "for clf_name, clf in classifiers.items():\n",
    "    # Entrenar el clasificador con los conjuntos preprocesados\n",
    "    clf.fit(X_train_preprocessed, y_train)\n",
    "    print(\"Entrenando\", clf_name)\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred = clf.predict(X_test_preprocessed)\n",
    "    print(\"Entrenado\", clf_name)\n",
    "\n",
    "    # Calcular las métricas y guardar los resultados\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    metric_results.append(\n",
    "        {\n",
    "            \"Model_name\": clf_name,\n",
    "            \"Model\": clf,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-score\": f1,\n",
    "        }\n",
    "        )\n",
    "\n",
    "    # Imprimir el reporte de clasificación para cada clasificador\n",
    "    print(f\"Classification Report for {clf_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Convertir la lista de resultados de métricas a un DataFrame\n",
    "metrics_df = pd.DataFrame(metric_results)\n",
    "\n",
    "# Ordenar el DataFrame según los valores de la métrica seleccionada (por ejemplo, Accuracy)\n",
    "selected_metric = \"Accuracy\"\n",
    "sorted_metrics_df = metrics_df.sort_values(by=selected_metric, ascending=False)\n",
    "\n",
    "print(\"Results sorted by\", selected_metric)\n",
    "display(sorted_metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que, en términos de precisión, todos los clasificadores superan al clasificador Dummy, lo que demuestra que no se limitan a realizar suposiciones aleatorias. El clasificador más efectivo es el LightGBM, que logra una precisión del 0.78. La superioridad de LightGBM sobre otros clasificadores puede atribuirse a su naturaleza como modelo de ensamble, lo que le permite combinar múltiples modelos para generar una predicción final más precisa.\n",
    "\n",
    "En la sección siguiente, se implementará una búsqueda de cuadrícula junto con un método para equilibrar las clases, con el objetivo de identificar los parámetros óptimos. Para optimizar el tiempo de procesamiento de la búsqueda de cuadrícula, se utilizarán solo dos modelos: LightGBM y XGBoost, los cuales demostraron tener las mejores métricas en el pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECCIÓN 5: Entrenamiento con los mejores modelos y tuning de hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un nuevo pipeline, el cual contempla diversos casos para ambos tipos de datos. Ademas se incluye un metodo de sub\\over sampling al modelo para que las clases esten balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los transformadores para datos numéricos y categóricos\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown= 'ignore'))\n",
    "])\n",
    "\n",
    "# Crear el preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Definir el resampler\n",
    "resampler = SMOTE()\n",
    "\n",
    "# Crear el pipeline de entrenamiento\n",
    "train_pipeline = ImbPipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('sampler', resampler),\n",
    "    ('model', LGBMClassifier(verbose = -1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una grilla que contemple ambos modelos definidos anteriormente con multiples parametros. Tanto en terminos de sampleo como hiperparametros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    # grilla 1: LightGBM\n",
    "    {\n",
    "        'preprocessing__num__imputer__strategy': ['median', 'mean', 'most_frequent'],\n",
    "        'preprocessing__cat__onehot__handle_unknown': ['infrequent_if_exist','ignore'],\n",
    "        'sampler': [RandomUnderSampler(), SMOTE(k_neighbors=2), None],\n",
    "        \"model\": [LGBMClassifier(random_state=seed, verbose= -1)],\n",
    "        'model__learning_rate': [0.1, 0.01, 0.001],\n",
    "        'model__n_estimators': [100, 500, 1000],\n",
    "        'model__num_leaves': [31, 50, 100],\n",
    "    },\n",
    "    # grilla 2: XGBoost\n",
    "    {\n",
    "        'preprocessing__num__imputer__strategy': ['median', 'mean', 'most_frequent'],\n",
    "        'preprocessing__cat__onehot__handle_unknown': ['infrequent_if_exist','ignore'],\n",
    "        'sampler': [RandomUnderSampler(), SMOTE(k_neighbors=2), None],\n",
    "        \"model\": [XGBClassifier(random_state=seed, eval_metric='mlogloss')],\n",
    "        'model__n_estimators': [100, 200, 500],\n",
    "        'model__max_depth': [10, 20, None],\n",
    "        'model__learning_rate': [0.1, 0.01],\n",
    "        'model__min_child_weight': [1, 3, 5],\n",
    "        'model__subsample': [0.8, 1.0],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen los parametros del grid_search, donde nos quedamos con la mejor balanced accuracy al ser este un problema con desbalanceo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HalvingGridSearchCV(\n",
    "    train_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='balanced_accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    min_resources= 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 100\n",
      "max_resources_: 9463\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2430\n",
      "n_resources: 100\n",
      "Fitting 5 folds for each of 2430 candidates, totalling 12150 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 810\n",
      "n_resources: 300\n",
      "Fitting 5 folds for each of 810 candidates, totalling 4050 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 270\n",
      "n_resources: 900\n",
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 90\n",
      "n_resources: 2700\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 30\n",
      "n_resources: 8100\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = False\n",
    "\n",
    "if Train:\n",
    "    search.fit(X_train, y_train)\n",
    "    dump(search.best_estimator_, 'best_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo\n",
    "best_model = load('best_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=3, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=500, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=42, ...), 'model__learning_rate': 0.01, 'model__max_depth': None, 'model__min_child_weight': 3, 'model__n_estimators': 500, 'model__subsample': 0.8, 'preprocessing__cat__onehot__handle_unknown': 'ignore', 'preprocessing__num__imputer__strategy': 'median', 'sampler': RandomUnderSampler()}\n",
      "Best score: 0.752307617861111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the best parameters\n",
    "best_params = search.best_params_\n",
    "\n",
    "# Get the best score\n",
    "best_score = search.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80       736\n",
      "           1       0.55      0.70      0.62       316\n",
      "\n",
      "    accuracy                           0.74      1052\n",
      "   macro avg       0.70      0.73      0.71      1052\n",
      "weighted avg       0.76      0.74      0.75      1052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utiliza el modelo con los mejores parámetros para hacer predicciones\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "# Genera el informe de clasificación\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECCIÓN 6: interpretabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m importance \u001b[39m=\u001b[39m best_model\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfeature_importances_\n\u001b[1;32m      5\u001b[0m \u001b[39m# Gráfico de barras de la importancia de las características\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mbar([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(importance))], importance)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importance = best_model.named_steps['model'].feature_importances_\n",
    "\n",
    "# Gráfico de barras de la importancia de las características\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
